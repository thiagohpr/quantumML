{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb03fb1-db76-44f1-9b79-d858d44a6792",
   "metadata": {},
   "source": [
    "# Projeto - Introdução à Computação Quântica\n",
    "\n",
    "### Desenvolvedores:\n",
    "* José Rafael Martins Fernandes\n",
    "* Thiago Hampl Pierri da Rocha\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Os *kernel algorithms* desempenham um papel crucial em *machine learning*, permitindo a transformação de dados complexos em espaços de alta dimensão, tornando possível a resolução de problemas não linearmente separáveis. No entanto, o desenvolvimento destes algoritmos utilizando a computação clássica enfrenta desafios significativos quando se trata de lidar com grandes conjuntos de dados e tarefas complexas de *machine learning*. Dessa forma, a computação quântica pode ser uma utilizada como uma maneira de tentar melhorar o desempenho destes algoritmos. Assim, vamos analisar uma pesquisa recente que investiga a interseção entre os s *kernel algorithms* e a computação quântica, com um foco especial na avaliação das possíveis vantagens dos modelos quânticos em tarefas de aprendizado. \n",
    "\n",
    "## Revisão do Artigo\n",
    "\n",
    "No artigo *Power of data in quantum machine learning*, os autores exploram o campo da computação quântica para *machine learning* e buscam avaliar as possíveis vantagens de modelos quânticos em tarefas de aprendizado. Eles começam enfatizando que tarefas de aprendizado de máquina que envolvem dados podem ser significativamente diferentes de outras tarefas computacionais comumente estudadas no domínio da computação quântica. Apesar dessa diferença, os autores demonstram que modelos clássicos de aprendizado de máquina, quando fornecidos com dados, podem competir com modelos quânticos, mesmo em situações em que a complexidade computacional é alta para a computação clássica.\n",
    "\n",
    "Para avaliar as possíveis vantagens de modelos quânticos em tarefas de aprendizado, os autores introduzem o conceito de uma diferença geométrica, que mede a dissimilaridade entre modelos de *machine learning* clássicos e quânticos com base em suas medidas de similaridade. Eles demonstram como essa diferença geométrica pode ser calculada e usada como uma ferramenta para avaliar o potencial de vantagem quântica na previsão. Se a diferença geométrica for pequena, espera-se que os modelos clássicos de aprendizado de máquina forneçam um desempenho semelhante ou até superior aos modelos quânticos, independentemente dos valores ou rótulos de funções específicas. Por outro lado, uma grande diferença geométrica indica o potencial de uma vantagem quântica.\n",
    "\n",
    "Assim, os autores realizam experimentos numéricos em conjuntos de dados projetados. Os resultados mostram que os modelos clássicos podem superar os modelos quânticos quando a diferença geométrica é pequena. No entanto, os autores também demonstram que um modelo quântico projetado pode apresentar uma significativa vantagem de previsão sobre os modelos clássicos quando a diferença geométrica é grande. Os experimentos destacam o papel dos dados na determinação das vantagens dos modelos de aprendizado de máquina quântica e enfatizam o potencial dos modelos quânticos projetados em fornecer um aumento na velocidade quântica em tarefas de aprendizado específicas.\n",
    "\n",
    "## Nosso projeto\n",
    "\n",
    "O objetivo do projeto consiste em empregar os experimentos mencionados no artigo a fim de verificar ou refutar as conclusões relativas às previsões entre os modelos clássicos e quânticos. Uma vez que o referido artigo aborda as condições que favorecem cada um desses modelos com base na geometria dos dados, planejamos aplicar tanto Kernels Clássicos quanto Quantum Kernels para avaliar tais vantagens, enquanto também examinamos a capacidade de previsão dos modelos quânticos em situações com diferenças significativas na geometria dos dados. Além disso, pretendemos realizar testes em múltiplas bases de dados, a fim de compreender a variabilidade dos resultados e demonstrar o impacto da estrutura dos dados nas conclusões do artigo.\n",
    "\n",
    "## Problema\n",
    "\n",
    "O principal desafio que enfrentamos no âmbito deste projeto reside na árdua tarefa de conduzir uma pesquisa para identificar e selecionar as bases de dados mais apropriadas que possam ser empregadas nas Provas de Conceito delineadas no artigo. Adicionalmente, nosso empenho se estende à aplicação de modelos tanto clássicos quanto quânticos, fazendo uso das bibliotecas que dão suporte a esses modelos, notadamente o scikit-learn e o Qiskit, a fim de alcançar resultados robustos e conclusivos em nossa análise.\n",
    "\n",
    "## Referências\n",
    "* https://www.nature.com/articles/s41467-021-22539-9\n",
    "* https://qiskit.org/ecosystem/machine-learning/tutorials/03_quantum_kernel.html\n",
    "* https://qiskit.org/ecosystem/machine-learning/tutorials/08_quantum_kernel_trainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit import Aer\n",
    "from qiskit.circuit.library import ZZFeatureMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_SVC(X, y, test_size=0.2, random_state=42):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Create an SVC model\n",
    "    svc_model = SVC(kernel='linear', random_state=random_state)\n",
    "\n",
    "    # Train the model\n",
    "    svc_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = svc_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantum_SVC(X, y, test_size=0.2, random_state=42):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    feature_map = ZZFeatureMap(feature_dimension=len(X.columns), reps=2, entanglement=\"linear\")\n",
    "\n",
    "    sampler = Sampler()\n",
    "\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "\n",
    "    quantum_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "\n",
    "    # Create the QSVC model\n",
    "    qsvc_model = QSVC(quantum_kernel=quantum_kernel)\n",
    "    \n",
    "    # Train the QSVC model\n",
    "    qsvc_model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    y_pred = qsvc_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>...</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0           120.0          0.000             0.0                 0.000   \n",
       "1           132.0          0.006             0.0                 0.006   \n",
       "2           133.0          0.003             0.0                 0.008   \n",
       "3           134.0          0.003             0.0                 0.008   \n",
       "4           132.0          0.007             0.0                 0.008   \n",
       "5           134.0          0.001             0.0                 0.010   \n",
       "6           134.0          0.001             0.0                 0.013   \n",
       "7           122.0          0.000             0.0                 0.000   \n",
       "8           122.0          0.000             0.0                 0.002   \n",
       "9           122.0          0.000             0.0                 0.003   \n",
       "\n",
       "   light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                0.000                   0.0                     0.000   \n",
       "1                0.003                   0.0                     0.000   \n",
       "2                0.003                   0.0                     0.000   \n",
       "3                0.003                   0.0                     0.000   \n",
       "4                0.000                   0.0                     0.000   \n",
       "5                0.009                   0.0                     0.002   \n",
       "6                0.008                   0.0                     0.003   \n",
       "7                0.000                   0.0                     0.000   \n",
       "8                0.000                   0.0                     0.000   \n",
       "9                0.000                   0.0                     0.000   \n",
       "\n",
       "   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                             73.0                                   0.5   \n",
       "1                             17.0                                   2.1   \n",
       "2                             16.0                                   2.1   \n",
       "3                             16.0                                   2.4   \n",
       "4                             16.0                                   2.4   \n",
       "5                             26.0                                   5.9   \n",
       "6                             29.0                                   6.3   \n",
       "7                             83.0                                   0.5   \n",
       "8                             84.0                                   0.5   \n",
       "9                             86.0                                   0.3   \n",
       "\n",
       "   percentage_of_time_with_abnormal_long_term_variability  ...  histogram_min  \\\n",
       "0                                               43.0       ...           62.0   \n",
       "1                                                0.0       ...           68.0   \n",
       "2                                                0.0       ...           68.0   \n",
       "3                                                0.0       ...           53.0   \n",
       "4                                                0.0       ...           53.0   \n",
       "5                                                0.0       ...           50.0   \n",
       "6                                                0.0       ...           50.0   \n",
       "7                                                6.0       ...           62.0   \n",
       "8                                                5.0       ...           62.0   \n",
       "9                                                6.0       ...           62.0   \n",
       "\n",
       "   histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes  \\\n",
       "0          126.0                        2.0                         0.0   \n",
       "1          198.0                        6.0                         1.0   \n",
       "2          198.0                        5.0                         1.0   \n",
       "3          170.0                       11.0                         0.0   \n",
       "4          170.0                        9.0                         0.0   \n",
       "5          200.0                        5.0                         3.0   \n",
       "6          200.0                        6.0                         3.0   \n",
       "7          130.0                        0.0                         0.0   \n",
       "8          130.0                        0.0                         0.0   \n",
       "9          130.0                        1.0                         0.0   \n",
       "\n",
       "   histogram_mode  histogram_mean  histogram_median  histogram_variance  \\\n",
       "0           120.0           137.0             121.0                73.0   \n",
       "1           141.0           136.0             140.0                12.0   \n",
       "2           141.0           135.0             138.0                13.0   \n",
       "3           137.0           134.0             137.0                13.0   \n",
       "4           137.0           136.0             138.0                11.0   \n",
       "5            76.0           107.0             107.0               170.0   \n",
       "6            71.0           107.0             106.0               215.0   \n",
       "7           122.0           122.0             123.0                 3.0   \n",
       "8           122.0           122.0             123.0                 3.0   \n",
       "9           122.0           122.0             123.0                 1.0   \n",
       "\n",
       "   histogram_tendency  fetal_health  \n",
       "0                 1.0           2.0  \n",
       "1                 0.0           1.0  \n",
       "2                 0.0           1.0  \n",
       "3                 1.0           1.0  \n",
       "4                 1.0           1.0  \n",
       "5                 0.0           3.0  \n",
       "6                 0.0           3.0  \n",
       "7                 1.0           3.0  \n",
       "8                 1.0           3.0  \n",
       "9                 1.0           3.0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/fetal_health_data.csv\", header = 0)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "X = df.drop(\"fetal_health\", axis=1)\n",
    "y = df[\"fetal_health\"]\n",
    "\n",
    "accuracy_fetal_health, y_pred_fetal_health = classic_SVC(X, y)\n",
    "print(f\"Accuracy of the SVC model: {accuracy_fetal_health}\")\n",
    "\n",
    "# accuracy_fetal_health_quantum_svc, y_fetal_health_pred_quantum_svc = quantum_SVC(X, y)\n",
    "# print(f\"Accuracy of the Quantum SVC model: {accuracy_fetal_health_quantum_svc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   compactness_mean  concavity_mean  symmetry_mean  fractal_dimension_mean  \\\n",
       "0           0.27760         0.30010         0.2419                 0.07871   \n",
       "1           0.07864         0.08690         0.1812                 0.05667   \n",
       "2           0.15990         0.19740         0.2069                 0.05999   \n",
       "3           0.28390         0.24140         0.2597                 0.09744   \n",
       "4           0.13280         0.19800         0.1809                 0.05883   \n",
       "5           0.17000         0.15780         0.2087                 0.07613   \n",
       "6           0.10900         0.11270         0.1794                 0.05742   \n",
       "7           0.16450         0.09366         0.2196                 0.07451   \n",
       "8           0.19320         0.18590         0.2350                 0.07389   \n",
       "9           0.23960         0.22730         0.2030                 0.08243   \n",
       "\n",
       "   diagnosis  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  \n",
       "8          1  \n",
       "9          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/breast_cancer_data.csv\", header = 0)\n",
    "\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "\n",
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\n",
    "df = df[[\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"symmetry_mean\", \"fractal_dimension_mean\", \"diagnosis\"]]\n",
    "\n",
    "X = df.drop(\"diagnosis\", axis=1)\n",
    "y = df[\"diagnosis\"]\n",
    "\n",
    "accuracy_breast_cancer, y_pred_breast_cancer = classic_SVC(X, y)\n",
    "print(f\"Accuracy of the SVC model: {accuracy_breast_cancer}\")\n",
    "\n",
    "# accuracy_breast_cancer_quantum_svc, y_breast_cancer_pred_quantum_svc = quantum_SVC(X, y)\n",
    "# print(f\"Accuracy of the Quantum SVC model: {accuracy_breast_cancer_quantum_svc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54d787c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVC model: 0.8780487804878049\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/credit_card.csv\", header = 0)\n",
    "y = pd.read_csv(\"data/credit_card_label.csv\", header = 0)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.drop(['Housing_type', 'Type_Occupation', 'Type_Income'], axis = 1)\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['GENDER', 'Car_Owner', 'Propert_Owner', 'EDUCATION', 'Marital_status'])\n",
    "\n",
    "df_encoded = pd.merge(df_encoded, y, on='Ind_ID', how='inner')\n",
    "\n",
    "X = df_encoded.drop(\"label\", axis=1)\n",
    "y = df_encoded[\"label\"]\n",
    "\n",
    "accuracy_credit_card, y_pred_credit_card = classic_SVC(X, y)\n",
    "print(f\"Accuracy of the SVC model: {accuracy_credit_card}\")\n",
    "\n",
    "# accuracy_credit_card_quantum_svc, y_credit_card_pred_quantum_svc = quantum_SVC(X, y)\n",
    "# print(f\"Accuracy of the Quantum SVC model: {accuracy_credit_card_quantum_svc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
